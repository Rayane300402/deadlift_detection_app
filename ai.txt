#AI Trends
    1-Explainable AI
    2-Generative AI
    3-Edge Computing AI
    4-Autonomous Driving AI
    5-Federated Learning
    ##What is explainable AI?
        Explainable AI (XAI) refers to methods and techniques in the application of artificial intelligence technology (AI) such that the results of the solution can be understood by human experts. It contrasts with the concept of the "black box" in machine learning where even their designers cannot explain why the AI arrived at a specific decision.
    ##What is generative AI?
        Generative AI is one of the biggest recent advancements in artificial intelligence technology because of its ability to create something new. It opens the door to an entire world of possibilities for human and computer creativity, with practical applications emerging across industries, from turning sketches into images for accelerated product development, to improving computer-aided design of complex objects. It takes two neural networks against each other to produce new and original digital works based on sample inputs. 
    ##What is edge computing AI?
        Edge computing is a distributed computing paradigm that brings computation and data storage closer to the location where it is needed, to improve response times and save bandwidth. Edge computing pushes applications, data and computing power (services) away from centralized points to the logical extremes of a network. It enables analytics and data gathering to occur at the source of the data. This approach requires leveraging resources that may not be continuously connected to a network such as laptops, smartphones, tablets and sensors. Edge computing covers a wide range of technologies such as wireless sensor networks, mobile data acquisition, mobile signature analysis, cooperative distributed peer-to-peer ad hoc networking and processing also classifiable as local cloud/fog computing and grid/mesh computing, dew computing, mobile edge computing, cloudlet, distributed data storage and retrieval, autonomic self-healing networks, remote cloud services, augmented reality, and more.
    ##What is autonomous driving AI?
        Autonomous driving is a technology in which a vehicle can operate without human intervention. It is a combination of various techniques such as radar, lidar, GPS, odometry, and computer vision. Autonomous cars use a variety of techniques to detect their surroundings, such as radar, laser light, GPS, odometry, and computer vision. Advanced control systems interpret sensory information to identify appropriate navigation paths, as well as obstacles and relevant signage. Autonomous cars have control systems that are capable of analyzing sensory data to distinguish between different cars on the road, which is very useful in planning a path to the desired destination.
    ##What is federated learning?    
        Federated learning is a machine learning technique that trains an algorithm across multiple decentralized edge devices or servers holding local data samples, without exchanging them. This approach stands in contrast to traditional centralized machine learning techniques where all the local datasets are uploaded to one server, as well as to more classical decentralized approaches which often assume that local data samples are identically distributed. Federated learning enables multiple actors to build a common, robust machine learning model without sharing data, thus addressing critical issues such as data privacy, data security, data access rights and access to heterogeneous data. Will help dedect money laundering, fraud, and other financial crimes.


#What is the difference between AI and ML?
    Artificial Intelligence (AI) is the broader concept of machines being able to carry out tasks in a way that we would consider “smart”. Machine Learning (ML) is a current application of AI based around the idea that we should really just be able to give machines access to data and let them learn for themselves. 
#What is the difference between AI and Deep Learning?
    Deep learning is a subset of machine learning that uses multi-layered artificial neural networks to deliver state-of-the-art accuracy in tasks such as object detection, speech recognition, language translation and others. Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We review the current status of AI applications in healthcare and discuss its future.


#Future Trends
    ##Human Augmentation
        Human augmentation is the use of technology to enhance a person’s cognitive and physical experiences. Physical augmentation changes an inherent physical capability by implanting or hosting a technology within or on the body. For example, the insertion of pacemakers in the body.
    ##Open AI Ecosystem
        Open AI Ecosystem is a system that consists of multiple subsystems, which are connected to serve a common goal. The goal of the Open AI Ecosystem is to create a system that is capable of performing tasks that are currently only possible for humans.
    ##Quantum Computing
        Quantum computing is the use of quantum phenomena such as superposition and entanglement to perform computation. Computers that perform quantum computations are known as quantum computers. Quantum computers are believed to be able to solve certain computational problems, such as integer factorization (which underlies RSA encryption), substantially faster than classical computers.
    ##AGI (Artificial General Intelligence)
        Artificial general intelligence (AGI) is the hypothetical intelligence of a machine that has the capacity to understand or learn any intellectual task that a human being can. It is a primary goal of some artificial intelligence research and a common topic in science fiction and future studies. Some researchers refer to Artificial general intelligence as "strong AI", "full AI" or as the ability of a machine to perform "general intelligent action"; others reserve "strong AI" for machines capable of experiencing consciousness.
    ##Brain Computer Interface
        A brain–computer interface (BCI), sometimes called a neural-control interface (NCI), mind-machine interface (MMI), direct neural interface (DNI), or brain–machine interface (BMI), is a direct communication pathway between an enhanced or wired brain and an external device. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing human cognitive or sensory-motor functions.        

#What is AI in theory?
    Artificial intelligence (AI) is the ability of a computer program or a machine to think and learn. It is also a field of study which tries to make computers "smart". They work on their own without being encoded with commands. AI is the study of how human intelligence thinks, works, learns, and feels. AI is a branch of computer science that aims to create intelligent machines. It has become an essential part of the technology industry. Research associated with artificial intelligence is highly technical and specialized. The core problems of artificial intelligence include programming computers for certain traits such as: Knowledge Reasoning Problem solving Perception Learning Planning Ability to manipulate and move objects
    ##Definition of AI
        Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions) and self-correction. Particular applications of AI include expert systems, speech recognition and machine vision.Artificial intelligence (AI) is wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence. AI is an interdisciplinary science with multiple approaches, but advancements in machine learning and deep learning are creating a paradigm shift in virtually every sector of the tech industry. AI is a branch of computer science that aims to create intelligent machines. It has become an essential part of the technology industry. Research associated with artificial intelligence is highly technical and specialized. The core problems of artificial intelligence include programming computers for certain traits such as: Knowledge Reasoning Problem solving Perception Learning Planning Ability to manipulate and move objects. Any machine that is able to perceive, make sense of something that is typically require human intelligence such as: learning, reasoning, solving perception, NLP.
    ##What is Intelligence?
        it's about perception, NLP, reasoning, learning, Problem-solving we are asking what is this not how is this, it's building an answer, based off of what we usually ask. It's about the ability to learn, understand, and make judgments or have opinions that are based on reason. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests). It's about the ability to learn or understand or to deal with new or trying situations. It's about the ability to apply knowledge to manipulate one's environment or to think abstractly as measured by objective criteria (such as tests).

#What is AI in practice?
    Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions) and self-correction. Particular applications of AI include expert systems, speech recognition and machine vision. Artificial intelligence (AI) is wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence. AI is an interdisciplinary science with multiple approaches, but advancements in machine learning and deep learning are creating a paradigm shift in virtually every sector of the tech industry. AI is a branch of computer science that aims to create intelligent machines. It has become an essential part of the technology industry. Research associated with artificial intelligence is highly technical and specialized. The core problems of artificial intelligence include programming computers for certain traits such as: Knowledge Reasoning Problem solving Perception Learning Planning Ability to manipulate and move objects

    ##AI has the ability to draw logical conclusion
        Experts systems (Mycon and Dendral) are the first AI systems that can draw logical conclusions. (Systems kbar, 3ala unis done  aw hospitals -> can't include all vendors cz fi vendors super freaking specific and this system is not wide spread yet and very expensive)
        we have diagnosis system, that can diagnose a disease based on symptoms. (MYCIN, IBM Watson)
    ##AI has the ability to find solutions from complex problems (search)
        we have search algorithms that can find solutions from complex problems. (GPS, Google search)
        resource allocation (scheduling, planning, etc.) (Amazon, UPS)
    ##Ability to perceive & interpret sensory information
        via sensors for example (find out person via scanning face or iris) with Facial Recogntion and shift
    ##Ability to understand and produce language
        NLP (Natural Language Processing) (Alexa, Siri, Google Assistant, ChatGPT)
        there's also language translation (Google Translate) -> considered as AI (asks people if translation is correct -> that's learning)

#key Components
    ##ML
        Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves. The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers learn automatically without human intervention or assistance and adjust actions accordingly. Some machine learning methods Supervised learning Unsupervised learning Reinforcement learning.
            ###Types of ML
                ####Supervised learning
                    Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see inductive bias). This statistical quality of an algorithm is measured through the so-called generalization error. The task of the supervised learning algorithm is to approximate the unknown mapping function (f) from input variables (X) to output variables (Y), i.e., learn a mapping function (f) that approximates the mapping so well that when you have new input data (x) that you can predict the output variables (Y) for that data. It is called supervised learning because the process of an algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. We know the correct answers, the algorithm iteratively makes predictions on the training data and is corrected by the teacher. Learning stops when the algorithm achieves an acceptable level of performance. Supervised learning problems can be further grouped into regression and classification problems. Classification: A classification problem is when the output variable is a category, such as “red” or “blue” or “disease” and “no disease”. Regression: A regression problem is when the output variable is a real value, such as “dollars” or “weight”. Some popular examples of supervised machine learning algorithms are: Linear regression Logistic regression Naive Bayes classifier K-nearest neighbor (KNN) Decision tree Random forest Support Vector Machine (SVM)
                ####Unsupervised learning
                    Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data. The clusters are modeled using a measure of similarity which is defined upon metrics such as Euclidean or probabilistic distance. In unsupervised learning, the algorithms are left to themselves to discover interesting structures in the data. It is often harder to understand than supervised learning because there is no feedback based on the prediction results. Unsupervised learning problems can be further grouped into clustering and association problems. Clustering: A clustering problem is where you want to discover the inherent groupings in the data, such as grouping customers by purchasing behavior. Association: An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people that buy X also tend to buy Y. Some popular examples of unsupervised learning algorithms are: k-means for clustering Apriori algorithm for association rule learning
                ####Reinforcement learning
                    Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge). The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques. The main difference between the classical techniques and reinforcement learning algorithms is that the latter do not need knowledge about the MDP and they target large MDPs where exact methods become infeasible. Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP, and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent. Reinforcement learning differs from standard supervised learning in that correct input/output pairs are never presented, nor sub-optimal actions explicitly corrected. Further, there is a focus on on-line performance, which involves finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge). The exploration vs. exploitation trade-off in reinforcement learning has been most thoroughly studied through the multi-armed bandit problem and in finite Markov decision processes. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent. Reinforcement learning differs from standard supervised learning in that correct input/output pairs are never presented, nor sub-optimal actions explicitly corrected. Further, there is a focus on on-line performance, which involves finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge). The exploration vs. exploitation trade-off in reinforcement learning has been most thoroughly studied through the multi-armed bandit problem and in finite Markov decision processes. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent. Reinforcement learning differs from standard supervised learning in that correct input/output pairs are never presented, nor sub-optimal actions explicitly corrected. Further, there is a focus on on-line performance, which involves finding a balance between exploration (of uncharted territory) and exploitation (of given data).
            ###ML Algorithms
                ####Regression
                    Predication of prices depending on geolocation for example + sizing of house(nbr. of rooms) + furniture or not. Very simple, old not as efficient.
                ####DL
                ####Decision tree
                ####Neural Networks
                    

    ##NLP 
        focuses on interaction between humans & computers using natural language. 
        ###Subfields of NLP
            ###Sentimental analysis
                Sentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. Sentiment analysis allows businesses to identify customer sentiment toward products, brands or services in online conversations and feedback...
        ###IRL Scenarios
            ###Chatbots
            ###Social Media Monitoring
                example instagram, if the pic has blood it gets blurred automatically, and asks users if they want to see it or not. Like a censor.
            ###Voice assistants
        ###Key techniques & model used
            word embedding, Neural machine translation
            ###word embedding
                Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing (NLP) where words or phrases from the vocabulary are mapped to vectors of real numbers. Conceptually it involves a mathematical embedding from a space with many dimensions per word to a continuous vector space with a much lower dimension.
            ###neural machine translation
            ###sentiment analysis

    ##Computer Vision
        Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do. Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory. Computer vision has also been described as the enterprise of automating and integrating a wide range of processes and representations for vision perception.        

        ###IRL Scenarios
            ###Face recognition
            ###Object detection
            ###Image classification
            ###Image segmentation
            ###Image restoration
            ###Video analysis
            ###Medical image analysis
            ###Autonomous vehicles
        ###Key techniques & model used
            ###Convolutional Neural Networks
                Convolutional Neural Networks (CNN) are a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, brain-computer interfaces, and financial time series.
            ###Generative Adversarial Networks
                Generative adversarial networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework. They were introduced by Ian Goodfellow et al. in 2014. This technique can generate photographs that look at least superficially authentic to human observers, having many realistic characteristics (though in tests people can tell real from generated in many cases). It is a generative model: it produces new data instances that resemble the training data. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers. GANs have been used to produce samples of photorealistic images for
        

#What is the difference between CNN and RNN?
    Convolutional Neural Networks (CNN) are used primarily for image classification and object detection tasks whereas Recurrent Neural Networks (RNN) are used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc. CNNs are mostly used for image classification and object detection tasks. RNNs are mostly used for text classification, speech recognition, language translation, etc.


